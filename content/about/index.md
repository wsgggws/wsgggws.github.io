+++
title = "简历"
date = 2024-10-16T11:30:03+00:00
+++

# 田海军

**男 | 30岁 | 本科/吉首大学-网络工程 | 深圳**

- **Python / Go Web 开发工程师，8年+工作经验**
- **手机（微信同号）**: 18820930503
- **Email**: <wsgggws@gmail.com>
- **GitHub**: [https://github.com/wsgggws](https://github.com/wsgggws)

---

## 个人简介

毕业于吉首大学，具备扎实的数据结构和算法基础，曾积极参与ACM竞赛，也在B站上分享算法相关知识。自2016年起在3家公司积累了丰富的Python Web开发和数据爬取与解析经验，主要负责大规模数据抓取、分布式调度系统、API设计及构建CI/CD流程。擅长Python和Go语言，注重代码质量、文档和自动化测试。构建监控和告警系统，通过数据驱动，提升系统可靠性并持续为业务和团队创造价值，注重客户成功。

---

## 技能清单

- **Python Web 后端**: Tornado, FastAPI, Gunicorn, OOP
- **数据获取与解析**: Requests, Scrapy, Aiohttp, Splash, Selenium, XPath, JSONPath, JmesPath, Pydantic
- **语言**: Python, Go, C, Rust
- **数据库**: MySQL, MongoDB, Redis, BigQuery, Spanner
- **测试**: UnitTest, TDD, Mock, Faker, PyTest, Locust
- **工具**: Google, Git, NeoVim, Raycast, Markdown, Linux, Docker, GCP, Agile, Jira, Charles
- **前端**: JavaScript, HTML, CSS, React, Bootstrap

---

## 学习工作经历

- 2016-06 ~ 2018-03 北京至信普林科技有限公司 Python开发工程师
- 2018-03 ~ 2019-03 && 2020-08 ~2024-09 AfterShip(爱客科技（深圳）有限公司) Python后端开发工程师
- 2019-03 ~ 2020-08 云集科技有限公司 Python开发工程师

## 项目经验

### AfterShip（爱客科技深圳有限公司）

#### 项目一：Couriers API 系统

**时间**: 2018-03 ~ 2019-03 && 2020-08 ~ 2024-09  
**项目描述**:  
负责开发并优化 Couriers API 系统，实现异步非阻塞的订单追踪服务，实时响应全球 1000+ 电商网站的订单信息查询需求。系统支持高并发场景下的可靠数据获取与一致性验证，有效降低响应延迟并提升 API 服务质量。此项目旨在提供稳定、快速的订单追踪 API 服务，确保订单信息的实时性和完整性。

**关键技术**:

- Tornado / FastAPI：Web 框架。
- Scrapy / Aiohttp：实现电商数据的抓取和异步处理。
- Pydantic：构建数据验证层，确保数据一致性。
- Redis：缓存，提升响应速度，及时更新配置参数。
- Prometheus、Sentry：性能追踪，监控和告警。

**项目成果**:

- **高吞吐量与响应时间优化**:

  - 在单台服务器上，通过优化代码与系统架构，将吞吐量提升至 45 RPS，95% 请求的响应时间降至 200ms，极大提升了系统的并发处理能力。
  - 使用 Redis 缓存频繁访问的数据(时间解析规则)和 API 凭证，提升数据获取速度及实现更新解析策略。

- **性能优化与架构升级**:

  - 迁移 Tornado + Scrapy 架构至 FastAPI + Aiohttp + Pydantic，使用 Aiohttp 的长连接与会话缓存，使系统吞吐量提升约 20%。
  - 开发解析模板，自动生成 API 端点和字段映射，支持 1000+ 电商数据的标准化解析，降低维护成本，显著提升开发效率。
  - 利用 XPath、JMESPath、正则表达式等工具及 Pydantic 对数据验证，实现不同电商网站数据的统一解析，提升数据标准化效率。

- **监控与自动化告警**:

  - 引入 Prometheus 指标收集与 Sentry 集成监控，监测 API 请求量、错误率和延迟，并通过 Grafana 实现数据可视化与告警。
  - 系统上线后，故障告警响应时间缩短至 10 秒以内，配合 PagerDuty，提高了 API 服务的稳定性与客户体验。

#### 项目二：调度系统

**时间**: 2018-03 ~ 2019-03 && 2020-08 ~ 2024-09  
**项目描述**:  
负责开发并优化高并发调度系统，每 3 小时更新 5000 万+ 数据，保证数据的实时性与完整性。使用 Go 语言进行核心服务编写，并结合 LMSTFY (Let Me Schedule Task For You) 实现分布式调度与任务队列管理。项目旨在提供高效的任务分发、处理和监控功能，有效提升数据更新的速度和准确性。

**关键技术**:

- Go：编写核心服务，保证高并发下的任务调度性能。
- LMSTFY：实现多节点任务队列调度与分发，提升任务分配和管理效率。
- PubSub：利用消息队列进行初始任务获取及结果保存。

**项目成果**:

- **数据结构与调度策略**:

  - 设计并优化了适用于高并发环境的任务数据结构，结合 LMSTFY 提供的任务队列，将任务优先级、重试次数等参数封装进队列消息，实现了任务的高效分发。
  - 采用 **令牌桶**（Token Bucket）算法实现流量控制，避免系统过载。同时，通过配置可动态调整的权重分配机制，满足高峰期需求。

- **性能提升**:

  - 通过 LMSTFY 的分布式任务管理功能，任务重试率控制在 2% 以内，调度系统在高峰时段的并发处理量达到了 5000 请求/秒。
  - 通过负载均衡和延迟监控等手段，减少了任务调度中的瓶颈，系统稳定性提升至 99.98%。

- **自动化与监控**:
  - 实现了一套完善的自动化监控和告警系统，使用 Prometheus 进行实时数据采集，Grafana 展示关键数据指标，实现系统关键事件的自动化告警。

### 云集科技共享有限公司

#### 项目三：电商网站与 APP 商品数据抓取与 CICD 平台构建

**时间**: 2019-03 ~ 2020-08  
**项目描述**:  
负责开发爬虫系统，实现对京东、淘宝等电商平台商品数据的高效抓取，并搭建基于云集的 CICD 平台。此系统不仅支持动态数据的快速抓取，还通过自动化部署实现了测试和生产环境的高效发布，支持项目的稳定持续交付。

**关键技术**:

- 数据抓取：Kafka, Scrapy, MySQL, Redis，处理大量动态 URL 和数据存储。
- CICD 平台：Flask, Jenkins, Rancher, Harbor, Gitlab，自动化流程搭建与版本控制。
- 系统监控与日志：Sentry, ELK，用于实时错误告警与日志监控与告警。

**项目成果**:

- **高效数据抓取与数据更新**:

  - 实现每日 20 万+ 商品数据的动态 URL 爬取，为业务决策提供高覆盖的数据支持。
  - 运用 Kafka 消息队列和 Scrapy-Redis 分布式爬虫架构，确保系统能够灵活应对请求量高峰。

- **自动化测试与 CICD 流程构建**:

  - 完成测试与生产环境的自动化部署流程，搭建可视化 Web 管理界面，使开发与运维团队能够实时监控发布状态。
  - 通过 Jenkins 与 Gitlab 的集成实现自动化流水线构建，测试、发布效率提高 40%，新功能上线时间减少 25%，错误修复与迭代周期更短，显著优化了开发流程。

- **系统监控与告警优化**:

  - 集成 ELK 与 Sentry 进行日志监控和告警，通过可视化数据面板提供实时系统性能反馈，实现故障预警、根因追踪。
  - 实现精准的错误定位与日志归档，确保平台在高并发环境下的稳定性，减少发布过程中潜在错误的影响，有效提高了运维响应速度。

### 北京至信普林科技有限公司

#### 项目四：全国工商企业信息爬取与展示系统

**时间**: 2016-06 ~ 2018-03  
**项目描述**:  
负责设计并实现分布式云爬虫系统，支持对全国 31 个省份工商企业信息的全面爬取与数据展示。通过分布式调度和高效数据存储解决方案，系统支持大规模企业信息的快速爬取和实时展示，适应动态变化的业务需求。

**关键技术**:

- 数据爬取：RabbitMQ, Requests, Redis, Selenium, 分布式调度与代理池管理，支持大规模数据抓取。
- 后端：Django, MongoDB, MySQL，进行数据结构化存储和查询优化。
- 前端与部署：Bootstrap, Nginx, uWSGI, Supervisord, Fabric，实现实时查询与数据展示。

**项目成果**:

- **大规模数据采集与反爬突破**:

  - 实现了 35 台服务器的分布式爬取架构，日均抓取高峰达到 70 万条工商企业信息数据。通过 RabbitMQ 实现任务调度，将错误重爬率控制在 5% 以下，有效保障数据的时效性和完整性。
  - 使用 Redis 管理动态代理池和多级 IP 验证，结合 Selenium + Chromedriver 破解滑块验证码，使验证码破解成功率达到 90%，提高了数据采集效率。

- **高效的数据存储与查询优化**:

  - 使用 MongoDB 存储海量企业数据，优化查询索引，减少 30% 的查询响应时间；MySQL 用于核心结构化数据存储，支持高并发查询，满足业务快速查询的需求。
  - 数据存储方式支持数据的批量更新和历史查询，通过合理的数据分片与索引设计，系统更好的支持实时查询。

- **实时数据展示与 Web 界面优化**:

  - 基于 Django 和 Bootstrap 构建的 Web 界面支持多条件查询，提供了全国工商数据的实时展示和导出功能，满足了业务方的数据洞察需求。
  - 配置 Nginx 和 uWSGI 实现多进程部署，结合 Supervisord 进行实时监控与自动重启，提高系统稳定性和故障恢复能力。

- **自动化部署与运维监控**:

  - 使用 Fabric 实现多服务器环境的自动化部署与版本管理，提升了开发和运维效率。
